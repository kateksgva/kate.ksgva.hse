{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kateksgva/kate.ksgva.hse/blob/main/hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задача 1: разработка пайплайна предобработки текста с ООП\n",
        "\n",
        "#### Цель:\n",
        "Hазработать класс на Python с использованием принципов объектно-ориентированного программирования (ООП), который реализует пайплайн для предобработки текста\n",
        "\n",
        "#### Методы, которые должен реализовывать разработанный класс:\n",
        "1. Токенизация\n",
        "2. Лемматизация\n",
        "3. Удаление стоп-слов\n",
        "\n",
        "Инструкция содержит подробное описание процесса создания класса. Результат вашей работы разместите в одной ячейке ниже инструкции"
      ],
      "metadata": {
        "id": "LHe6Z-d9h1Ay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Инструкция\n",
        "\n",
        "**Создание класса**\n",
        "\n",
        "Определите класс `TextProcessor`, который будет содержать методы для предобработки текста.  \n",
        "\n",
        "```python\n",
        "# Создание базового класса для предобработки текста\n",
        "class TextProcessor:\n",
        "    def __init__(self, text):\n",
        "        \"\"\"\n",
        "        Инициализация класса с исходным текстом.\n",
        "        \"\"\"\n",
        "        self.text = text\n",
        "        self.tokens = []\n",
        "        self.cleaned_tokens = []\n",
        "```\n",
        "\n",
        "**Метод токенизации**\n",
        "\n",
        "Реализуйте метод, который разделяет текст на отдельные слова.\n",
        "\n",
        "```python\n",
        "    def tokenize(self):\n",
        "        \"\"\"\n",
        "        Метод для токенизации текста.\n",
        "        \"\"\"\n",
        "        # Реализуйте токенизацию здесь\n",
        "        pass\n",
        "```\n",
        "\n",
        "Пример вызова метода:  \n",
        "```python\n",
        "processor = TextProcessor(text)\n",
        "processor.tokenize()\n",
        "print(processor.tokens)\n",
        "```\n",
        "\n",
        "**Метод лемматизации**\n",
        "\n",
        "Добавьте метод, который преобразует слова к их леммам. Используйте `WordNetLemmatizer` из NLTK.\n",
        "\n",
        "```python\n",
        "    def lemmatize(self):\n",
        "        \"\"\"\n",
        "        Метод для лемматизации токенов.\n",
        "        \"\"\"\n",
        "        # Реализуйте лемматизацию здесь\n",
        "        pass\n",
        "```\n",
        "\n",
        "Пример вызова метода:  \n",
        "```python\n",
        "processor.lemmatize()\n",
        "print(processor.cleaned_tokens)\n",
        "```\n",
        "\n",
        "**Метод удаления стоп-слов**\n",
        "\n",
        "Добавьте метод для удаления стоп-слов из токенов. Используйте список стоп-слов из NLTK.\n",
        "\n",
        "```python\n",
        "    def remove_stopwords(self):\n",
        "        \"\"\"\n",
        "        Метод для удаления стоп-слов.\n",
        "        \"\"\"\n",
        "        # Реализуйте удаление стоп-слов здесь\n",
        "        pass\n",
        "```\n",
        "\n",
        "Пример вызова метода:  \n",
        "```python\n",
        "processor.remove_stopwords()\n",
        "print(processor.cleaned_tokens)\n",
        "```\n",
        "\n",
        "**Запуск пайплайна**\n",
        "\n",
        "Объедините все шаги в пайплайн. Добавьте вызов каждого метода по порядку:\n",
        "\n",
        "```python\n",
        "processor = TextProcessor(text)\n",
        "processor.tokenize()\n",
        "processor.remove_stopwords()\n",
        "processor.lemmatize()\n",
        "\n",
        "# Вывод итогового результата\n",
        "print(\"Токены:\", processor.tokens)\n",
        "print(\"Лемматизированные токены:\", processor.cleaned_tokens)\n",
        "```"
      ],
      "metadata": {
        "id": "Z4PuMmgPimOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ВАШЕ РЕШЕНИЕ ЗДЕСЬ\n",
        "# Установка нужных библиотек из nltk\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Загружаем необходимые ресурсы\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Загружаем файл с текстом\n",
        "!wget    https://raw.githubusercontent.com/kateksgva/kate.ksgva.hse/refs/heads/main/text%20hw1\n",
        "with open(\"text hw1\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "#  Создание базового класса для работы с текстом, задаем пустые списки\n",
        "class TextProcessor:\n",
        "    def __init__(self):\n",
        "        self.text = text\n",
        "        self.tokens = []\n",
        "        self.cleaned_tokens = []\n",
        "        self.lemmatized_tokens = []\n",
        "\n",
        "# Токенизируем текст\n",
        "    def tokenize(self):\n",
        "        self.tokens = word_tokenize(self.text)\n",
        "        return self.tokens\n",
        "# Лемматизируем\n",
        "    def lemmatize(self):\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        self.lemmatized_tokens = [lemmatizer.lemmatize(token) for token in self.cleaned_tokens]\n",
        "        return self.lemmatized_tokens\n",
        "# Удаление стоп-слов\n",
        "    def remove_stopwords(self):\n",
        "        self.cleaned_tokens = [token for token in self.tokens if token not in stop_words]\n",
        "        return self.cleaned_tokens\n",
        "\n",
        "\n",
        "processor = TextProcessor()\n",
        "processor.tokenize()\n",
        "processor.remove_stopwords()\n",
        "processor.lemmatize()\n",
        "\n",
        "\n",
        "# Выводим результаты\n",
        "print(\"Токены:\", processor.tokens)\n",
        "print(\"Очищенные токены:\", processor.cleaned_tokens) # Выводим cleaned_tokens после remove_stopwords\n",
        "print(\"Лемматизированные токены:\", processor.lemmatized_tokens)\n"
      ],
      "metadata": {
        "id": "UHqMdoUip-We",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94b9a84-c456-4066-ba17-d32635a28e22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-05 17:51:10--  https://raw.githubusercontent.com/kateksgva/kate.ksgva.hse/refs/heads/main/text%20hw1\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2563 (2.5K) [text/plain]\n",
            "Saving to: ‘text hw1.4’\n",
            "\n",
            "\rtext hw1.4            0%[                    ]       0  --.-KB/s               \rtext hw1.4          100%[===================>]   2.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-05 17:51:10 (40.3 MB/s) - ‘text hw1.4’ saved [2563/2563]\n",
            "\n",
            "Токены: ['Miss', 'Pettigrew', 'pushed', 'open', 'the', 'door', 'of', 'the', 'employment', 'agency', 'and', 'went', 'in', 'as', 'the', 'clock', 'struck', 'a', 'quarter', 'past', 'nine', '.', 'She', 'had', ',', 'as', 'usual', ',', 'very', 'little', 'hope', ',', 'but', 'today', 'the', 'Principal', 'greeted', 'her', 'with', 'a', 'more', 'cheerful', 'smile', '.', '“', 'Ah', '!', 'Miss', 'Pettigrew', '.', 'I', 'think', 'we', 'have', 'something', 'for', 'you', 'today', '.', 'Two', 'came', 'in', 'when', 'I', 'had', 'left', 'last', 'night', '.', 'Now', 'let', 'me', 'see', '.', 'Ah', 'yes', '!', 'Mrs.', 'Hilary', ',', 'maid', '.', 'Miss', 'LaFosse', ',', 'nursery', 'governess', '.', 'Hmn', '!', 'You', '’', 'd', 'have', 'thought', 'it', 'was', 'the', 'other', 'way', 'round', '.', 'But', 'there', '!', 'I', 'expect', 'she', '’', 's', 'an', 'aunt', 'with', 'an', 'adopted', 'orphan', 'niece', ',', 'or', 'something.', '”', 'She', 'gave', 'Miss', 'Pettigrew', 'particulars', '.', '“', 'There', 'you', 'are', 'then', '.', 'Miss', 'LaFosse', ',', '5', ',', 'Onslow', 'Mansions', '.', 'The', 'appointment', 'is', 'for', 'ten', 'sharp', 'this', 'morning', '.', 'You', '’', 'll', 'make', 'it', 'nicely.', '”', '“', 'Oh', 'thank', 'you', ',', '”', 'Miss', 'Pettigrew', 'said', 'weakly', ',', 'nearly', 'fainting', 'with', 'relief', '.', 'She', 'clutched', 'the', 'card', 'of', 'particulars', 'firmly', 'in', 'her', 'hand', '.', '“', 'I', '’', 'd', 'nearly', 'given', 'up', 'hope', '.', 'Not', 'many', 'of', 'my', 'kind', 'of', 'post', 'these', 'days.', '”', '“', 'Not', 'many', ',', '”', 'agreed', 'Miss', 'Holt', ',', 'and', ',', 'as', 'the', 'door', 'closed', 'behind', 'Miss', 'Pettigrew', ',', '“', 'I', 'hope', 'that', '’', 's', 'the', 'last', 'I', 'see', 'of', 'her', ',', '”', 'thought', 'Miss', 'Holt', '.', 'Outside', 'on', 'the', 'pavement', 'Miss', 'Pettigrew', 'shivered', 'slightly', '.', 'It', 'was', 'a', 'cold', ',', 'grey', ',', 'foggy', 'November', 'day', 'with', 'a', 'drizzle', 'of', 'rain', 'in', 'the', 'air', '.', 'Her', 'coat', ',', 'of', 'a', 'nondescript', ',', 'ugly', 'brown', ',', 'was', 'not', 'very', 'thick', '.', 'It', 'was', 'five', 'years', 'old', '.', 'London', 'traffic', 'roared', 'about', 'her', '.', 'Pedestrians', 'hastened', 'to', 'reach', 'their', 'destinations', 'and', 'get', 'out', 'of', 'the', 'depressing', 'atmosphere', 'as', 'quickly', 'as', 'possible', '.', 'Miss', 'Pettigrew', 'joined', 'the', 'throng', ',', 'a', 'middle-aged', ',', 'rather', 'angular', 'lady', ',', 'of', 'medium', 'height', ',', 'thin', 'through', 'lack', 'of', 'good', 'food', ',', 'with', 'a', 'timid', ',', 'defeated', 'expression', 'and', 'terror', 'quite', 'discernible', 'in', 'her', 'eyes', ',', 'if', 'any', 'one', 'cared', 'to', 'look', '.', 'But', 'there', 'was', 'no', 'personal', 'friend', 'or', 'relation', 'in', 'the', 'whole', 'world', 'who', 'knew', 'or', 'cared', 'whether', 'Miss', 'Pettigrew', 'was', 'alive', 'or', 'dead', '.', 'Miss', 'Pettigrew', 'went', 'to', 'the', 'bus-stop', 'to', 'await', 'a', 'bus', '.', 'She', 'could', 'not', 'afford', 'the', 'fare', ',', 'but', 'she', 'could', 'still', 'less', 'afford', 'to', 'lose', 'a', 'possible', 'situation', 'by', 'being', 'late', '.', 'The', 'bus', 'deposited', 'her', 'about', 'five', 'minutes', '’', 'walk', 'from', 'Onslow', 'Mansions', ',', 'and', 'at', 'seven', 'minutes', 'to', 'ten', 'precisely', 'she', 'was', 'outside', 'her', 'destination', '.', 'It', 'was', 'a', 'very', 'exclusive', ',', 'very', 'opulent', ',', 'very', 'intimidating', 'block', 'of', 'flats', '.', 'Miss', 'Pettigrew', 'was', 'conscious', 'of', 'her', 'shabby', 'clothes', ',', 'her', 'faded', 'gentility', ',', 'her', 'courage', 'lost', 'through', 'weeks', 'of', 'facing', 'the', 'workhouse', '.', 'She', 'stood', 'a', 'moment', '.', 'She', 'prayed', 'silently', '.', '“', 'Oh', 'Lord', '!', 'If', 'I', '’', 've', 'ever', 'doubted', 'your', 'benevolence', 'in', 'the', 'past', ',', 'forgive', 'me', 'and', 'help', 'me', 'now.', '”', 'She', 'added', 'a', 'rider', 'to', 'her', 'prayer', ',', 'with', 'the', 'first', 'candid', 'confession', 'she', 'had', 'ever', 'made', 'to', 'her', 'conscious', 'mind', '.', '“', 'It', '’', 's', 'my', 'last', 'chance', '.', 'You', 'know', 'it', '.', 'I', 'know', 'it', '.', '”']\n",
            "Очищенные токены: ['Miss', 'Pettigrew', 'pushed', 'open', 'door', 'employment', 'agency', 'went', 'clock', 'struck', 'quarter', 'past', 'nine', '.', 'She', ',', 'usual', ',', 'little', 'hope', ',', 'today', 'Principal', 'greeted', 'cheerful', 'smile', '.', '“', 'Ah', '!', 'Miss', 'Pettigrew', '.', 'I', 'think', 'something', 'today', '.', 'Two', 'came', 'I', 'left', 'last', 'night', '.', 'Now', 'let', 'see', '.', 'Ah', 'yes', '!', 'Mrs.', 'Hilary', ',', 'maid', '.', 'Miss', 'LaFosse', ',', 'nursery', 'governess', '.', 'Hmn', '!', 'You', '’', 'thought', 'way', 'round', '.', 'But', '!', 'I', 'expect', '’', 'aunt', 'adopted', 'orphan', 'niece', ',', 'something.', '”', 'She', 'gave', 'Miss', 'Pettigrew', 'particulars', '.', '“', 'There', '.', 'Miss', 'LaFosse', ',', '5', ',', 'Onslow', 'Mansions', '.', 'The', 'appointment', 'ten', 'sharp', 'morning', '.', 'You', '’', 'make', 'nicely.', '”', '“', 'Oh', 'thank', ',', '”', 'Miss', 'Pettigrew', 'said', 'weakly', ',', 'nearly', 'fainting', 'relief', '.', 'She', 'clutched', 'card', 'particulars', 'firmly', 'hand', '.', '“', 'I', '’', 'nearly', 'given', 'hope', '.', 'Not', 'many', 'kind', 'post', 'days.', '”', '“', 'Not', 'many', ',', '”', 'agreed', 'Miss', 'Holt', ',', ',', 'door', 'closed', 'behind', 'Miss', 'Pettigrew', ',', '“', 'I', 'hope', '’', 'last', 'I', 'see', ',', '”', 'thought', 'Miss', 'Holt', '.', 'Outside', 'pavement', 'Miss', 'Pettigrew', 'shivered', 'slightly', '.', 'It', 'cold', ',', 'grey', ',', 'foggy', 'November', 'day', 'drizzle', 'rain', 'air', '.', 'Her', 'coat', ',', 'nondescript', ',', 'ugly', 'brown', ',', 'thick', '.', 'It', 'five', 'years', 'old', '.', 'London', 'traffic', 'roared', '.', 'Pedestrians', 'hastened', 'reach', 'destinations', 'get', 'depressing', 'atmosphere', 'quickly', 'possible', '.', 'Miss', 'Pettigrew', 'joined', 'throng', ',', 'middle-aged', ',', 'rather', 'angular', 'lady', ',', 'medium', 'height', ',', 'thin', 'lack', 'good', 'food', ',', 'timid', ',', 'defeated', 'expression', 'terror', 'quite', 'discernible', 'eyes', ',', 'one', 'cared', 'look', '.', 'But', 'personal', 'friend', 'relation', 'whole', 'world', 'knew', 'cared', 'whether', 'Miss', 'Pettigrew', 'alive', 'dead', '.', 'Miss', 'Pettigrew', 'went', 'bus-stop', 'await', 'bus', '.', 'She', 'could', 'afford', 'fare', ',', 'could', 'still', 'less', 'afford', 'lose', 'possible', 'situation', 'late', '.', 'The', 'bus', 'deposited', 'five', 'minutes', '’', 'walk', 'Onslow', 'Mansions', ',', 'seven', 'minutes', 'ten', 'precisely', 'outside', 'destination', '.', 'It', 'exclusive', ',', 'opulent', ',', 'intimidating', 'block', 'flats', '.', 'Miss', 'Pettigrew', 'conscious', 'shabby', 'clothes', ',', 'faded', 'gentility', ',', 'courage', 'lost', 'weeks', 'facing', 'workhouse', '.', 'She', 'stood', 'moment', '.', 'She', 'prayed', 'silently', '.', '“', 'Oh', 'Lord', '!', 'If', 'I', '’', 'ever', 'doubted', 'benevolence', 'past', ',', 'forgive', 'help', 'now.', '”', 'She', 'added', 'rider', 'prayer', ',', 'first', 'candid', 'confession', 'ever', 'made', 'conscious', 'mind', '.', '“', 'It', '’', 'last', 'chance', '.', 'You', 'know', '.', 'I', 'know', '.', '”']\n",
            "Лемматизированные токены: ['Miss', 'Pettigrew', 'pushed', 'open', 'door', 'employment', 'agency', 'went', 'clock', 'struck', 'quarter', 'past', 'nine', '.', 'She', ',', 'usual', ',', 'little', 'hope', ',', 'today', 'Principal', 'greeted', 'cheerful', 'smile', '.', '“', 'Ah', '!', 'Miss', 'Pettigrew', '.', 'I', 'think', 'something', 'today', '.', 'Two', 'came', 'I', 'left', 'last', 'night', '.', 'Now', 'let', 'see', '.', 'Ah', 'yes', '!', 'Mrs.', 'Hilary', ',', 'maid', '.', 'Miss', 'LaFosse', ',', 'nursery', 'governess', '.', 'Hmn', '!', 'You', '’', 'thought', 'way', 'round', '.', 'But', '!', 'I', 'expect', '’', 'aunt', 'adopted', 'orphan', 'niece', ',', 'something.', '”', 'She', 'gave', 'Miss', 'Pettigrew', 'particular', '.', '“', 'There', '.', 'Miss', 'LaFosse', ',', '5', ',', 'Onslow', 'Mansions', '.', 'The', 'appointment', 'ten', 'sharp', 'morning', '.', 'You', '’', 'make', 'nicely.', '”', '“', 'Oh', 'thank', ',', '”', 'Miss', 'Pettigrew', 'said', 'weakly', ',', 'nearly', 'fainting', 'relief', '.', 'She', 'clutched', 'card', 'particular', 'firmly', 'hand', '.', '“', 'I', '’', 'nearly', 'given', 'hope', '.', 'Not', 'many', 'kind', 'post', 'days.', '”', '“', 'Not', 'many', ',', '”', 'agreed', 'Miss', 'Holt', ',', ',', 'door', 'closed', 'behind', 'Miss', 'Pettigrew', ',', '“', 'I', 'hope', '’', 'last', 'I', 'see', ',', '”', 'thought', 'Miss', 'Holt', '.', 'Outside', 'pavement', 'Miss', 'Pettigrew', 'shivered', 'slightly', '.', 'It', 'cold', ',', 'grey', ',', 'foggy', 'November', 'day', 'drizzle', 'rain', 'air', '.', 'Her', 'coat', ',', 'nondescript', ',', 'ugly', 'brown', ',', 'thick', '.', 'It', 'five', 'year', 'old', '.', 'London', 'traffic', 'roared', '.', 'Pedestrians', 'hastened', 'reach', 'destination', 'get', 'depressing', 'atmosphere', 'quickly', 'possible', '.', 'Miss', 'Pettigrew', 'joined', 'throng', ',', 'middle-aged', ',', 'rather', 'angular', 'lady', ',', 'medium', 'height', ',', 'thin', 'lack', 'good', 'food', ',', 'timid', ',', 'defeated', 'expression', 'terror', 'quite', 'discernible', 'eye', ',', 'one', 'cared', 'look', '.', 'But', 'personal', 'friend', 'relation', 'whole', 'world', 'knew', 'cared', 'whether', 'Miss', 'Pettigrew', 'alive', 'dead', '.', 'Miss', 'Pettigrew', 'went', 'bus-stop', 'await', 'bus', '.', 'She', 'could', 'afford', 'fare', ',', 'could', 'still', 'less', 'afford', 'lose', 'possible', 'situation', 'late', '.', 'The', 'bus', 'deposited', 'five', 'minute', '’', 'walk', 'Onslow', 'Mansions', ',', 'seven', 'minute', 'ten', 'precisely', 'outside', 'destination', '.', 'It', 'exclusive', ',', 'opulent', ',', 'intimidating', 'block', 'flat', '.', 'Miss', 'Pettigrew', 'conscious', 'shabby', 'clothes', ',', 'faded', 'gentility', ',', 'courage', 'lost', 'week', 'facing', 'workhouse', '.', 'She', 'stood', 'moment', '.', 'She', 'prayed', 'silently', '.', '“', 'Oh', 'Lord', '!', 'If', 'I', '’', 'ever', 'doubted', 'benevolence', 'past', ',', 'forgive', 'help', 'now.', '”', 'She', 'added', 'rider', 'prayer', ',', 'first', 'candid', 'confession', 'ever', 'made', 'conscious', 'mind', '.', '“', 'It', '’', 'last', 'chance', '.', 'You', 'know', '.', 'I', 'know', '.', '”']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Критерии оценивания**\n",
        "\n",
        "- **Отсутствие ошибок в ООП:** класс корректно инициализируется и выполняет все методы без ошибок (2 балла).  \n",
        "- **Реализован метод токенизации:** текст корректно разделяется на токены (2 балла).  \n",
        "- **Реализован метод лемматизации:** все токены преобразованы к леммам (2 балла).  \n",
        "- **Реализован метод удаления стоп-слов:** стоп-слова корректно удалены из токенов (2 балла).  \n",
        "- **Класс протестирован:** все методы вызваны, код работает (2 балла).  \n",
        "\n",
        "Общий балл: **10 баллов**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Примечания**\n",
        "\n",
        "- Добавьте текстовые ячейки в Colab и комментарии с описанием этапов выполнения.\n",
        "- Комментарии не оцениваются, но они важны для вашей работы и воспроизводимости кода\n",
        "- Проверьте, что все методы выполняются корректно на примере любого текста.\n",
        "- Пример текста для проверки работы пайплайна: `https://github.com/vifirsanova/compling/blob/main/tasks/task1/data.txt`."
      ],
      "metadata": {
        "id": "Kk81rQiAqBjr"
      }
    }
  ]
}
